
# local_textql
Local LLM App with Streamlit and Ollama 
Text to SQL chat built on Llama3.2 prepared for GCP Dataset 'thelook_ecommerce'. When you can't share prorietary information to a LLM online, ollama provides a local and appropriate (albeit slow) alternative to prompt it with your schema and get query suggestions based on your questions.

## To begin using:
Begin with installing Python and starting a virtual environment.

<a href="(https://ollama.com/download)">Install ollama</a>

Clone the repository:
```
git clone https://github.com/Ethanlchandler/local_textql
```

